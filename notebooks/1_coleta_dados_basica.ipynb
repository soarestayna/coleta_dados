{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Web Scraping com Requests, BeautifulSoup e Pandas\n",
    "\n",
    "### Este notebook faz parte do portfólio acadêmico do curso de Análise de Dados - EBAC"
   ],
   "id": "696b99e705264215"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### O objetivo étrair informações de uma página da web, interpretar o HTML e organizar os dados em tabelas para análise.",
   "id": "46b9a4e4753a6fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ### 1. Importando bibliotecas\n",
    "\n",
    "- `requests` - Permite fazer requisições HTTP para acessar o conteúdo de páginas da web, como se fosse o navegador pedindo para ver uma página — só que feito por código.\n",
    "> - `requests.get(url)` - acessa a página\n",
    "> - `response.text` - extrai o conteúdo HTML da resposta\n",
    "\n",
    "- `from bs4 import BeautifulSoup` - Serve para interpretar e navegar pelo HTML de uma página, facilita encontrar elementos específicos como tabelas, títulos, links.\n",
    "> - `BeautifulSoup(html, 'html.parser')` - cria o objeto de análise\n",
    "> - `soup.find()`, `soup.select()` - localiza elementos no HTML\n",
    "> - `soup.prettify()` - exibe o HTML de forma organizada\n",
    "\n",
    "- `Pandas` - É uma biblioteca *muito utilizada* para análise e manipulação de dados.\n",
    "No contexto de web scraping, ela consegue extrair tabelas HTML diretamente.\n",
    "> - `pandas.read_html(url)` - extrai todas as tabelas da página\n",
    "> - `DataFrame.head()` - mostra as primeiras linhas\n",
    "> - `DataFrame.to_csv()` - salva os dados em arquivo CSV\n"
   ],
   "id": "19c567c69431f136"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Criando cabeçalho para simular navegador\n",
    "\n",
    "- `headers` é um dicionário que simula o comportamento de um navegador real."
   ],
   "id": "f0794c474019af34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64/ x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36'\n",
    "}"
   ],
   "id": "771710410d8229cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Fazendo requisição HTTP\n",
    "\n",
    "- `requests.get()` - Usado para acessar o conteúdo da página.\n",
    "- `headers=headers` - O cabeçalho evita bloqueios por parte do servidor.\n",
    "- `response.text[:600]` - Exibe os primeiros 600 caracteres do HTML"
   ],
   "id": "e6947ee1932daca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('Request: ')\n",
    "response = requests.get('https://webscraper.io/test-sites/tables/tables-semantically-correct', headers=headers)\n",
    "print(response.text[:600])"
   ],
   "id": "2e8cadad36773dbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Interpretando o HTML com BeautifulSoup\n",
    "\n",
    "- `BeautifulSoup` - organiza o HTML, facilitando a visualização da estrutura da página.\n",
    "- `soup.prettify()[:1000]` - Exibe os primeiros 1000 caracteres do HTML formatado"
   ],
   "id": "8405f4c15c015c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('BeautifulSoup: ')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup.prettify()[:1000])"
   ],
   "id": "3a153f9cff8c8448"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Extraindo tabelas com Pandas\n",
    "\n",
    "- `pandas.read_html()` - identifica e extrai automaticamente todas as tabelas da página. O resultado é uma lista de DataFrames.\n",
    "- `url_dados[0].head(10)` - Exibe as 10 primeiras linhas da primeira tabela"
   ],
   "id": "3dfa5763f1267b7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "url_dados = pandas.read_html('https://webscraper.io/test-sites/tables/tables-semantically-correct')\n",
    "print(url_dados[0].head(10))"
   ],
   "id": "989cefa6cb9ac8aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
